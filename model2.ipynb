{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1</td>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>ff669174</td>\n",
       "      <td>0</td>\n",
       "      <td>Limiting car usage has many advantages. Such a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>ffa247e0</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>ffc237e9</td>\n",
       "      <td>0</td>\n",
       "      <td>As we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>ffe1ca0d</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1378 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1     005db917          0  Transportation is a large necessity in most co...   \n",
       "2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3     00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...        ...        ...                                                ...   \n",
       "1373  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n",
       "1374  ff669174          0  Limiting car usage has many advantages. Such a...   \n",
       "1375  ffa247e0          0  There's a new trend that has been developing f...   \n",
       "1376  ffc237e9          0  As we all know cars are a big part of our soci...   \n",
       "1377  ffe1ca0d          0  Cars have been around since the 1800's and hav...   \n",
       "\n",
       "      generated  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "1373          0  \n",
       "1374          0  \n",
       "1375          0  \n",
       "1376          0  \n",
       "1377          0  \n",
       "\n",
       "[1378 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('Data/train_essays/train_essays.csv')\n",
    "\n",
    "# Display the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Drop the last column from the test data\n",
    "test_df = test_df.iloc[:, :-1]\n",
    "\n",
    "# Create a directory to save the temporary data\n",
    "os.makedirs('Data/temporary', exist_ok=True)\n",
    "\n",
    "# Save the training and testing data\n",
    "train_df.to_csv('Data/temporary/Temp_Train_Data.csv', index=False)\n",
    "test_df.to_csv('Data/temporary/Temp_Test_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing data\n",
    "train_df = pd.read_csv('Data/temporary/Temp_Train_Data.csv')\n",
    "test_df = pd.read_csv('Data/temporary/Temp_Test_Data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e0dbb2e7</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars, they make life so much easier, or, do th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3d75a33b</td>\n",
       "      <td>0</td>\n",
       "      <td>Now a days you see everyone with cars driving ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6049a24f</td>\n",
       "      <td>1</td>\n",
       "      <td>Presidential election is held every after four...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cecf6e5e</td>\n",
       "      <td>1</td>\n",
       "      <td>I dont think that the electoral college should...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>669e6f61</td>\n",
       "      <td>0</td>\n",
       "      <td>How could we get the reduction of Greenhouse G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>c7c1cf69</td>\n",
       "      <td>0</td>\n",
       "      <td>People all over the world are saying goodbye t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>cf8af518</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear state senator, I believe that we shouldn'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>f01dd0a6</td>\n",
       "      <td>0</td>\n",
       "      <td>The modern automobile has been the axle to the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>9b753df1</td>\n",
       "      <td>1</td>\n",
       "      <td>The Electoral College is a process that should...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>cef0572a</td>\n",
       "      <td>0</td>\n",
       "      <td>There is a new age coming,and with that means ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     e0dbb2e7          0  Cars, they make life so much easier, or, do th...   \n",
       "1     3d75a33b          0  Now a days you see everyone with cars driving ...   \n",
       "2     6049a24f          1  Presidential election is held every after four...   \n",
       "3     cecf6e5e          1  I dont think that the electoral college should...   \n",
       "4     669e6f61          0  How could we get the reduction of Greenhouse G...   \n",
       "...        ...        ...                                                ...   \n",
       "1097  c7c1cf69          0  People all over the world are saying goodbye t...   \n",
       "1098  cf8af518          1  Dear state senator, I believe that we shouldn'...   \n",
       "1099  f01dd0a6          0  The modern automobile has been the axle to the...   \n",
       "1100  9b753df1          1  The Electoral College is a process that should...   \n",
       "1101  cef0572a          0  There is a new age coming,and with that means ...   \n",
       "\n",
       "      generated  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "1097          0  \n",
       "1098          0  \n",
       "1099          0  \n",
       "1100          0  \n",
       "1101          0  \n",
       "\n",
       "[1102 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the training data\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70d7c567</td>\n",
       "      <td>0</td>\n",
       "      <td>Can you imagine living in a place where there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81977e6c</td>\n",
       "      <td>0</td>\n",
       "      <td>Limiting car usage could have many advantages ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e43869b8</td>\n",
       "      <td>0</td>\n",
       "      <td>In this generation, our planet is getting filt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d33eca96</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a basic need for people today we use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71f7131e</td>\n",
       "      <td>1</td>\n",
       "      <td>Why do we keep this despised method of choosin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>62b480e1</td>\n",
       "      <td>0</td>\n",
       "      <td>The culture of the car has been coming to an e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>7405b110</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars, though useful, have negative impacts on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>47e743a7</td>\n",
       "      <td>0</td>\n",
       "      <td>The extensive use of car transportation is set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>95d41c3e</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you know what pollution is? Have you ever t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>ee6fb060</td>\n",
       "      <td>1</td>\n",
       "      <td>The Electoral Colleage is not a Colleage like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  prompt_id                                               text\n",
       "0    70d7c567          0  Can you imagine living in a place where there ...\n",
       "1    81977e6c          0  Limiting car usage could have many advantages ...\n",
       "2    e43869b8          0  In this generation, our planet is getting filt...\n",
       "3    d33eca96          0  Cars are a basic need for people today we use ...\n",
       "4    71f7131e          1  Why do we keep this despised method of choosin...\n",
       "..        ...        ...                                                ...\n",
       "271  62b480e1          0  The culture of the car has been coming to an e...\n",
       "272  7405b110          0  Cars, though useful, have negative impacts on ...\n",
       "273  47e743a7          0  The extensive use of car transportation is set...\n",
       "274  95d41c3e          0  Do you know what pollution is? Have you ever t...\n",
       "275  ee6fb060          1  The Electoral Colleage is not a Colleage like ...\n",
       "\n",
       "[276 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the testing data\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [01:31<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:01:44.26\n"
     ]
    }
   ],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define the function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize the words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words('english')]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Initialize tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Define a function to apply to the DataFrame\n",
    "def preprocess_df(df):\n",
    "    # Apply the preprocess_text function to the 'text' column with a progress bar\n",
    "    return df['text'].progress_apply(preprocess_text)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Preprocess the text\n",
    "train_df['text'] = preprocess_df(train_df)\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(train_df['text'].tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Convert words into numerical representations\n",
    "train_df['text'] = train_df['text'].apply(lambda text: [model.wv[word] for word in text])\n",
    "\n",
    "# Pad the sequences\n",
    "train_df['text'] = pad_sequences(train_df['text']).tolist()\n",
    "\n",
    "# Convert the list of sequences into a numpy array\n",
    "X = np.array(train_df['text'].tolist())\n",
    "\n",
    "# y is target variable\n",
    "y = np.array(train_df['generated'].tolist())\n",
    "\n",
    "# End the timer and print the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours, rem = divmod(elapsed_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(f\"Elapsed time: {int(hours):02d}:{int(minutes):02d}:{seconds:05.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 7s 239ms/step - loss: 0.1011 - accuracy: 0.9784 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 6s 213ms/step - loss: 0.0162 - accuracy: 0.9977 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 7s 249ms/step - loss: 0.0159 - accuracy: 0.9977 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 6s 211ms/step - loss: 0.0153 - accuracy: 0.9977 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 5s 191ms/step - loss: 0.0146 - accuracy: 0.9977 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 5s 188ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 6s 212ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 5s 188ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 5s 192ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 6s 208ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0013 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(100, input_shape=(None, 100)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 65ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "Accuracy: 99.90925788879395%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Load the model\n",
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [00:22<00:00, 12.06it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\LLM-Detect-AI-Generated-Text\\model2.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Preprocess the test data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preprocess_df(test_df)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test_df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m text: [model\u001b[39m.\u001b[39;49mwv[word] \u001b[39mfor\u001b[39;49;00m word \u001b[39min\u001b[39;49;00m text])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pad_sequences(test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Convert the list of sequences into a numpy array\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:4765\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4756\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4758\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4759\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   4760\u001b[0m         func,\n\u001b[0;32m   4761\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[0;32m   4762\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[0;32m   4763\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   4764\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m-> 4765\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1201\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[0;32m   1200\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1201\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1281\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[0;32m   1276\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[0;32m   1282\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[0;32m   1283\u001b[0m )\n\u001b[0;32m   1285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1286\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1287\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReturning a DataFrame from Series.apply when the supplied function \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1288\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturns a Series is deprecated and will be removed in a future \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1291\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1292\u001b[0m     )  \u001b[39m# GH52116\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\algorithms.py:1812\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1810\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1811\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1812\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[0;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1815\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[0;32m   1816\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32md:\\LLM-Detect-AI-Generated-Text\\model2.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Preprocess the test data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preprocess_df(test_df)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m text: [model\u001b[39m.\u001b[39;49mwv[word] \u001b[39mfor\u001b[39;49;00m word \u001b[39min\u001b[39;49;00m text])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pad_sequences(test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Convert the list of sequences into a numpy array\u001b[39;00m\n",
      "\u001b[1;32md:\\LLM-Detect-AI-Generated-Text\\model2.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Preprocess the test data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preprocess_df(test_df)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m text: [model\u001b[39m.\u001b[39;49mwv[word] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m text])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pad_sequences(test_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LLM-Detect-AI-Generated-Text/model2.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Convert the list of sequences into a numpy array\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "# Preprocess the test data\n",
    "test_df['text'] = preprocess_df(test_df)\n",
    "test_df['text'] = test_df['text'].apply(lambda text: [model.wv[word] for word in text])\n",
    "test_df['text'] = pad_sequences(test_df['text']).tolist()\n",
    "\n",
    "# Convert the list of sequences into a numpy array\n",
    "X_test = np.array(test_df['text'].tolist())\n",
    "y_test = np.array(test_df['generated'].tolist())\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
